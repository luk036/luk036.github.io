<!doctype html>
<html>
  <head>
    <title>Lecture 2c: Introduction to Convex Optimization</title>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"
    />
    <link rel="stylesheet" type="text/css" href="../katex/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../css/nord-dark.css" />
    <link rel="stylesheet" type="text/css" href="../css/nord-light.css" />
    <link rel="stylesheet" type="text/css" href="../css/font-nord.css" />
    <link rel="stylesheet" type="text/css" href="../css/bg-nord.css" />
    <link rel="stylesheet" type="text/css" href="../css/slides.css" />
  </head>
  <body>
    <textarea id="source">

layout: true
class: typo, typo-selection

---

count: false
class: nord-dark, middle, center

# ğŸ¯ Introduction to Convex Programming

@luk036 ğŸ‘¨ğŸ»â€ğŸ«

2024-09-18 ğŸ“…

---

ğŸ“ Abstract
----------

This lecture introduces convex programming and covers various optimization aspects. It commences with an optimization overview, including linear and nonlinear programming, duality, convexity, and approximation techniques. The lecture then proceeds with specific topics within continuous optimization, such as linear programming problems and their standard form, standard form transformations, and duality. The lecture covers nonlinear programming, examining the standard format of an NLPP (nonlinear programming problem) and the essential optimality requirements referred to as the Karush-Kuhn-Tucker (KKT) conditions. It also delves into the topic of convexity, defining convex functions and their characteristics. Moreover, the lecture covers the duality of convex optimization problems and their value in computation. Finally, the document discusses several optimization techniques, including unconstrained optimization, descent methods, and approximation methods when working with constraints.

---

Overview ğŸ“‹
-----------

.pull-left[

- **Introduction**
- **Linear programming**
- **Nonlinear programming**
- **Duality and Convexity**
- **Approximation techniques**
- **Convex Programming**
- **Books and online resources**

] .pull-right[

![image](figs/dfm.svg)

]

---

ğŸ” Classification of Optimizations
-------------------------------

- **Continuous**
    - Linear vs Non-linear
    - Convex vs Non-convex
- **Discrete**
    - Polynomial time Solvable
    - NP-hard
        - Approximatable
        - Non-approximatable
- **Mixed**

---

ğŸ“Š Venn Diagram of Continuous Optimization
-----------------------

![classification](lec02.files/class.svg)

---

ğŸ§® Linear Programming Problem
--------------------------

- An LPP in standard form is:
    $$\min\{ c^\mathsf{T} x \mid A x = b, x \ge 0\}.$$
- The ingredients of LPP are:
    - An $m \times n$ matrix $A$, with $n > m$
    - A vector $b \in \mathbb{R}^m$
    - A vector $c \in \mathbb{R}^n$

---

ğŸ“š Example
-------

$$\begin{array}{lll}
  \text{minimize} & 0.4 x_1 + 3.4 x_2 - 3.4 x_3 \\
  \text{subject to} & 0.5 x_1 + 0.5 x_2  & = 3.5 \\
  & 0.3 x_1 - 0.8 x_2 + 8.4 x_2 & = 4.5 \\
  & x_1, x_2, x_3 \ge 0
\end{array}$$

---

## ğŸ”„ Transform to Standard Form

- **Theorem**: Any LPP can be transformed into the standard form.
- Variables not restricted in sign:
    - Decompose $x$ to two new variables
        $x = x_1 - x_2, x_1, x_2 \geq 0$
- Transforming inequalities into equalities:
    - By putting slack variable $y = b - A x \geq 0$
    - Set $x' = (x, y), A' = (A, 1)$
- Transforming a max into a min
    - max(expression) = min($-$expression);

---

## ğŸ”„ Linearize the non-linear's

**Original Problem:**
$$(a +  b \cdot {\color{red} y}) x \leq 0, \; x > 0$$

**Transformation:**
Let $z = y \cdot x$. The problem becomes:
$$a \cdot x + b \cdot {\color{green} z} \leq 0, \; x > 0$$

**Post-proccessing:**
$$y_\text{opt} = z_\text{opt} x^{-1}_\text{opt}$$

---

## ğŸ”¢ Logarithmic Transformation

**Original Problem:**

$$\pi \leq {\color{red} x / y} \leq \phi, \; x > 0, y > 0$$

**Transformation:**
Let $z' = \log(z)$. The problem becomes:

$$\pi' \leq {\color{green} x' - y'} \leq \phi'$$

**Post-proccessing:**

$$z_\text{opt} = \exp(z'_\text{opt}).$$

---

âš–ï¸ Duality of LPP
--------------

- If the primal problem of the LPP:
    $\min\{ c^\mathsf{T} x \mid A x \ge b, x \ge 0\}$.
- Its dual is:
    $\max\{ y^\mathsf{T} b \mid A^\mathsf{T} y \leq c, y \ge 0\}$.
- If the primal problem is:
    $\min\{ c^\mathsf{T} x \mid A x = b, x \ge 0\}$.
- Its dual is: $\max\{ y^\mathsf{T} b \mid A^\mathsf{T} y \leq c\}$.

---

ğŸ“ˆ Nonlinear Programming
---------------------

- The standard form of an NLPP is
    $$\min\{f(x) \mid g(x) \leq 0, h(x)=0 \}.$$
- Necessary conditions of optimality, Karush- Kuhn-Tucker (KKT) conditions:
    - **Gradient Condition**: âˆ‡f(x) + Âµâˆ‡g(x) + Î»âˆ‡h(x) = 0
    - **Complementary Slackness Condition**: Âµg(x) = 0
    - **Feasibility Condition**: Âµ â‰¥ 0, g(x) â‰¤ 0, h(x) = 0

---

## ğŸ”ï¸ What is Convex Optimization?

- Convex optimization is a subfield of mathematical optimization that deals with problems where the objective function and the feasible region are both convex.

- A function $f$: $K \subseteq \mathbb{R}^n \mapsto R$ is convex if $K$ is a convex set and $f(y) \ge f(x) + \nabla f(x) (y - x), \; y,x \in K$.

- A problem is convex if the objective function $f(x)$ is convex and the feasible set defined by the constraints is a convex set.

- **Theorem**: Assume that $f$ and $g$ are convex differentiable functions. If the pair $(x, m)$ satisfies the KKT conditions above, $x$ is an optimal solution of the problem. If in addition, $f$ is strictly convex, $x$ is the only solution of the problem.

---

## ğŸ”‘ Key Characteristics

.pull-left[

1. **ğŸŒ Global Optimum**: Any local minimum is also a global minimum.
2. **âš¡ Efficient Algorithms**: Well-established algorithms like Gradient Descent, Interior-Point Methods, etc.
3. **ğŸ“Š Wide Applicability**: Used in machine learning, finance, engineering, etc.

] .pull-right[

![image](figs/local-global.png)

**(Local minimum == global minimum)**

]

---

## ğŸ“ Basic Formulation

A standard convex optimization problem can be formulated as:

$$
\begin{array}{ll}
    \text{minimize} & \quad f(x) \\
    \text{subject to} & \quad g_i(x) \leq 0, \quad i = 1, \ldots, m \\
        & \quad h_j(x) = 0, \quad j = 1, \ldots, p
\end{array}
$$

where $f(x)$ is convex, $g_i(x)$ are convex inequality constraints, and $h_j(x)$ are affine equality constraints.

---

## ğŸ”„ What is Quasi-convex Programming?

- An extension of convex optimization
- Deals with quasi-convex functions and sets
- Bridges the gap between convex and non-convex optimization

---

## ğŸ“š Example of Quasi-Convex Functions

- $\sqrt{|y|}$ is quasi-convex on $\mathbb{R}$
- $\log(y)$ is quasi-linear on $\mathbb{R}_{++}$
- $f(x, y) = x y$ is quasi-concave on $\mathbb{R}_{++}^2$
- Linear-fractional function:
    - $f(x)$ = $(a^\mathsf{T} x + b)/(c^\mathsf{T} x + d)$
    - dom $f$ = $\{x \,|\, c^\mathsf{T} x + d > 0 \}$
- Distance ratio function:
    - $f(x)$ = $\| x - a\|_2 / \| x - b \|_2$

---

## ğŸ› ï¸ Tools and Software

1. ğŸ–¥ï¸ CVX (MATLAB-based modeling system)
2. ğŸ CVXPY (Python-based modeling system)
3. ğŸ’¼ MOSEK (Commercial optimizer)
4. ğŸ“ˆ Gurobi (Commercial optimizer)
5. ğŸ”§ Custom EDA tools with integrated convex solvers

---

class: nord-light, middle, center

# ğŸ¨ Convexify the Non-convex's

---

## ğŸ“š Example: Convexifying a Simple Non-Convex Function

Consider the non-convex function:
$$f(x) = x^4 - 4x^2 + 4$$

**Transformation:**
Let $y = x^2$. The problem becomes:
$$f(y) = y^2 - 4y + 4$$

**Post-proccessing:**
$$x_\text{opt} = \pm\sqrt{y_\text{opt} }$$

---

## ğŸ”„ Change of curvature: square

**Original Problem:**
$${\color{red} x^2 } + {\color{red} y^2 } \geq 0.16 \quad \text{(non-convex)}$$

**Transformation:**
Let $x' = x^2$, $y' = y^2$. The problem becomes:
$${\color{green} x'} + {\color{green} y'} \geq 0.16, \quad x', y' \geq 0$$

**Post-proccessing:**
$$x_\text{opt} = \pm\sqrt{x'_\text{opt} }, \quad y_\text{opt} = \pm\sqrt{y'_\text{opt} }.$$

---

## ğŸ”„ Change of curvature: sine

**Original Problem:**
$${\color{red} \sin^2{x} } \leq 0.4, \quad 0 \leq x \leq \pi/2$$

**Transformation:**
$${\color{green} y} \leq 0.4, \quad 0 \leq y \leq 1$$

**Post-proccessing:**
$$x_\text{opt} = \sin^{-1}(\sqrt{y_\text{opt} }).$$

ğŸ‘‰ Note that $\sin(\cdot)$ are monotonic concave functions in $(0, \pi/2)$.

---

## ğŸ”„ Reciprocal Transformation

**Original Problem:**
$${\color{red} \log(x)} + 0.4 \leq 0, \; x > 0$$

**Transformation:**
Let $y = 1 / x$. The problem becomes:
$${\color{green} -\log(y)} + 0.4 \leq 0, \; y > 0 \, .$$

**Post-proccessing:**
$$x_\text{opt} = y^{-1}_\text{opt}.$$

ğŸ‘‰ Note that $\sqrt{\cdot}$, $\log(\cdot)$, and $(\cdot)^{-1}$ are monotonic functions.

---

## ğŸ§  Other thoughts

- Alternating minimization
- Replace non-convex constraint with sufficient condition
- Relaxation + heuristic
- Decomposition

---

## ğŸ¯ Conclusion

Convex programming provides a powerful framework for solving a wide range of optimization problems characterized by convex objective functions and convex feasible sets. The fundamental property that every local optimum is a global optimum, coupled with the existence of efficient solution algorithms, makes convex optimization a cornerstone in many scientific and engineering disciplines. This introduction has covered the basics of linear and nonlinear programming, the definition and key characteristics of convex optimization, the concept of quasi-convex programming, various transformation techniques to potentially convert non-convex problems into convex ones, fundamental unconstrained optimization methods, and approaches for handling constraints. The availability of robust software tools and comprehensive resources further enhances the practical utility of convex programming. Understanding these core concepts is essential for anyone seeking to tackle optimization problems in a rigorous and effective manner.

---

class: nord-dark, middle, center

.pull-left[

Q & A ğŸ™‹ï¸
========

] .pull-right[

![image](figs/questions-and-answers.svg)

]
    </textarea>
    <script src="../js/remark.min.js"></script>
    <script src="../katex/katex.min.js" type="text/javascript"></script>
    <script
      src="../katex/contrib/auto-render.min.js"
      type="text/javascript"
    ></script>
    <script type="text/javascript">
      renderMathInElement(document.getElementById("source"), {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
        ],
      });
      var slideshow = remark.create({
        ratio: "4:3", // çª—å£æ¯”ä¾‹
        // å¯é€‰ï¼šarta, ascetic, dark, default, far, github, googlecode, idea,
        // ir-black, magula, monokai, rainbow, solarized-dark, solarized-light,
        // sunburst, tomorrow, tomorrow-night-blue, tomorrow-night-bright,
        // tomorrow-night, tomorrow-night-eighties, vs, zenburn.
        highlightStyle: "tomorrow-night-eighties",
        highlightLines: true,
        countIncrementalSlides: false, // å¢é‡å†…å®¹æ˜¯å¦ç®—ä¸€é¡µ
        // slideNumberFormat: "", // è‹¥å°†æ­¤å‚æ•°è®¾ç½®ä¸º ""ï¼Œå°†ä¸æ˜¾ç¤ºé¡µç 
        navigation: {
          scroll: false, // æ˜¯å¦å…è®¸ä½¿ç”¨é¼ æ ‡æ»šè½®ç¿»é¡µ
          touch: true, // ï¼ˆå¦‚æœæ˜¯è§¦æ‘¸å±ï¼‰æ˜¯å¦å…è®¸ç‚¹å‡»å±å¹•å·¦è¾¹æˆ–å³è¾¹å‰åç¿»é¡µ
          click: false, // æ˜¯å¦å…è®¸é¼ æ ‡ç‚¹å‡»å±å¹•å·¦è¾¹æˆ–å³è¾¹å‰åç¿»é¡µ
        },
      });
    </script>
  </body>
</html>
