layout: true
class: typo, typo-selection

---

count: false
class: nord-dark, middle, center

# Coarse-Grained Reconfigurable Arrays (CGRAs): Architecture, Compilation, and Challenges ğŸ—ï¸ğŸ’»

@luk036 ğŸ‘¨â€ğŸ’»

2025-05-08 ğŸ“…

---

## Credit ğŸ™

*   **Title:** Coarse-Grained Reconfigurable Arrays (CGRAs): Architecture, Compilation, and Challenges ğŸ—ï¸ğŸ’»
*   **Presenters:** ğŸ‘¥ Zhaoying Li, Dhananjaya Wijerathne, and Tulika Mitra (Based on source authors)
*   **Affiliation:** ğŸ« National University of Singapore, Singapore
*   **Source:** ğŸ“š Excerpts from "Handbook of Computer Architecture"
*   **Target Audience:** ğŸ“ Potentially computer architecture students, researchers, or engineers interested in spatial accelerators.
*   **Estimated Time:** â³ 42 minutes

---

## Introduction - What is a CGRA? â“

*   A **promising class of spatial accelerator** ğŸš€
*   Offers **high performance, energy efficiency, and flexibility** âš¡ğŸ’
*   **Bridges the gap** ğŸŒ‰ between efficient but inflexible domain-specific accelerators (ASICs) and flexible but inefficient general-purpose processors
*   Essentially an **array of word-level processing elements (PEs)** ğŸ”¢ connected via on-chip interconnect
*   Both **PEs and interconnect are reconfigurable per cycle** ğŸ”„, driven by on-chip configuration memory
*   **Compiler maps compute-intensive loop kernels** ğŸ—ºï¸ onto the CGRA in a spatio-temporal fashion
*   Goal: **Hardware-like efficiency with software-like programmability** âš™ï¸ğŸ’»

---

## Why CGRAs? The Performance Gap

*   **General-Purpose Processors (CPUs):**
    *   Unlimited flexibility, can execute any application â™¾ï¸
    *   **Low performance and energy efficiency** ğŸ¢ due to overheads (fetching, decoding, dependencies) and difficulty extracting parallelism from sequential streams
    *   Performance growth limited by **power wall, ILP wall, and memory wall** ğŸ§± after decades of innovation (Moore's Law, Dennard Scaling, micro-architecture)
*   **Domain-Specific Accelerators (ASICs):**
    *   High performance and energy efficiency for specific tasks (DNNs, image processing, crypto) ğŸï¸
    *   **Zero flexibility** ğŸ”’ â€“ tied to one task or domain
    *   Feasible only for **ubiquitous tasks** ğŸŒ
    *   Prevalent in modern SoCs (e.g., Apple A8) ğŸ“±
*   **Reconfigurable Computing (including CGRAs):**
    *   A **compromise** âš–ï¸ between the two extremes
    *   ASIC-like efficiency while maintaining flexibility through **software programmability** ğŸ’¾

---

## CGRAs vs. FPGAs âš”ï¸

*   **Field-Programmable Gate Arrays (FPGAs):**
    *   Array of configurable logic blocks (computation) and programmable routing resources (interconnect) ğŸ§©
    *   **Fine bit-level granularity** of reconfiguration ğŸ”
    *   Higher cost in **area (20-35x ASIC), power (10x dynamic power), and delay (3-4x slower)** ğŸŒ compared to ASICs
    *   Reconfiguration can take a longer time interval â³
*   **CGRAs:**
    *   **Coarse-grained functional units** (word-level) ğŸ“
    *   **Per-cycle reconfigurability** ğŸ”„
    *   Achieve **higher performance and lower power** âš¡ compared to FPGAs
    *   Leverage **temporal configuration dimension** (per-cycle) allowing smaller spatial dimensions via time-multiplexing â±ï¸
    *   Smaller chip area, thus **lower power** (especially leakage) ğŸ’¡

---

## CGRA: Basic Components ğŸ§±

*   **Core elements:** Set of Processing Elements (PEs) and an on-chip network ğŸŒ
*   **Per-cycle reconfiguration:** Both PE operations and network routing ğŸ”„
*   **Classic 4x4 CGRA example:** (Refers to Fig 1 in source)
    *   **PEs:** Capable of arithmetic, logic, memory operations ğŸ§®
        *   Includes Functional Unit (FU), small Register File (RF), crossbar switches, and Configuration Memory ğŸ’¾
        *   Each FU can have ALUs or other units âš™ï¸
    *   **On-chip network:** Connects PEs ğŸ›£ï¸
    *   **On-chip Data Memory (SPM):** Feeds data to the PE array ğŸ½ï¸
        *   Data transfer with off-chip memory via DMA ğŸšš
    *   **Configuration Memory:** Stores per-cycle directives for PE modules (ALU, switches, RF ports) ğŸ—‚ï¸

---

## CGRA: Configuration and Execution âš™ï¸

*   PEs read configurations from memory each cycle ğŸ“–
*   **Sequence of configurations** for a limited number of cycles is stored on-chip ğŸ—ƒï¸
*   At runtime, this sequence is **repeated cyclically** ğŸ”
*   CGRA fabric configured in **spatial** (PE count) and **temporal** (configuration sequence length) domains ğŸ“â±ï¸
*   New configuration sequences can be loaded from external storage (with delay) â³
*   High performance from **parallelism** of many PEs ğŸ¤
*   Improved energy efficiency from **simple architecture** faithfully following pre-planned computation/routing by compiler ğŸ“

---

## CGRA: Variations ğŸ”€

*   **Homogeneous vs. Heterogeneous CGRAs:**
    *   **Homogeneous:** All PEs have the same functionality âš–ï¸
    *   **Heterogeneous:** PEs can have different functionalities ğŸ­
        *   Useful for specific domains (e.g., MAC for ML) ğŸ¤–
        *   Specialized PEs can be costly (area/power) ğŸ’°
        *   Heterogeneity often in **memory access** (boundary PEs access SPM) ğŸ§ 
        *   Other examples: SFUs for FP32 alongside integer PEs ğŸ”¢
        *   Design space exploration frameworks exist for heterogeneous CGRAs (e.g., REVAMP) ğŸ› ï¸

---

## CGRA: Spatial CGRA ğŸ—ºï¸

*   A special case with **only one configuration word** 1ï¸âƒ£
*   Area, power, and cycle time reduction (no reconfiguration delay) â¬
*   More energy-efficient than traditional CGRAs ğŸ’¡
*   **Lacks the temporal dimension** advantage â³
*   Essentially reduces to an FPGA but with coarse-grained units ğŸ§±
*   Limited configuration memory may require **loop partitioning and reloading** for large kernels ğŸ”„

---

## CGRA: On-Chip Network ğŸŒ

*   Connects PEs for data routing ğŸ›£ï¸
*   **Neighbor-to-neighbor (N2N):** Most common, PE connected to neighbors, reaches in one cycle â†”ï¸
    *   Routing distant PEs requires intermediate PEs and multiple cycles ğŸ¢
    *   Simple, but **limited interconnection**, requires great compilation effort
    *   Int. PEs routing transient data cannot compute in the same cycle ğŸš«
*   **Advanced Network (HyCUBE):**
    *   Single-cycle **multiple-hop connections** create larger virtual neighborhood ğŸš€
    *   Special **bypass network** allows int. PEs to forward data without consuming it ğŸ¯
    *   Reduces routing delay, improves compilation time & kernel run time â±ï¸
    *   Int. PEs in bypass path **can continue executing operations**
    *   Trade-off: Increasing hops per cycle reduces max clock frequency
*   **Scalability for larger CGRAs:** Tiled architectures with higher bandwidth between blocks (e.g., Plasticine) ğŸ§©

---

## CGRA: Memory Hierarchy ğŸ§ 

*   Two main types of memory:
    *   **Data Memory:** Input, output, intermediate data
    *   **Configuration Memory:** Configuration directives âš™ï¸
*   **On-chip Data Memory:**
    *   Typically **multi-bank Scratchpad Memory (SPM)** ğŸ¦
    *   **Fully software-controlled** (compiler manages data movement) ğŸ’¾
    *   More power-efficient than caches âš¡
    *   Multi-bank increases **data throughput** (parallel access) ğŸš€
    *   Limited read/write ports per bank ğŸšª
    *   Often **boundary PEs** have access to banks (Refers to Fig 4 in source) ğŸ—ï¸
    *   Some architectures use shared RFs between PEs for communication ğŸ’¬
*   **Configuration Memory (Context/Instruction Memory):**
    *   Holds per-cycle directives for PEs and switches ğŸ—‚ï¸
    *   Repeated sequence for accelerating loop kernels ğŸ”
    *   Loaded before execution â³
    *   Can be centralized (global) or decentralized (local per PE) ğŸŒ
    *   PEs execute in lockstep, sharing a program counter ğŸ”¢

---

## CGRA: CPU Interface ğŸ’»

*   CGRAs are **coupled with a host processor** to execute complete applications ğŸ¤
*   Host CPU responsibilities: non-loop code, CGRA configuration, DMA data transfers ğŸ—ï¸
*   **Tightly coupled:** CGRA part of main CPU (e.g., ADRES) ğŸ”—
    *   Cannot execute code in parallel on CPU/CGRA ğŸš«
*   **Loosely coupled:** CGRA is an independent accelerator (e.g., MorphoSys) (Refers to Fig 4 in source) ğŸª
    *   Offers more design flexibility ğŸ®
    *   CPU and CGRA can execute in parallel â±ï¸
    *   Higher data transfer overheads

---

## Compilation for CGRAs: The Goal ğŸ¯

*   **Input:** A loop from an application, a CGRA architecture ğŸ“¥
*   **Output:** Configurations for a fixed number of cycles (the mapping) ğŸ“¤
*   **Objective:** **Maximize throughput** ğŸš€
*   Loop represented as a **Dataflow Graph (DFG)**
    *   Nodes = operations, Edges = dependencies â†”ï¸
    *   Exposes computations and data flow ğŸŒŠ
*   Mapping involves finding **spatio-temporal coordinates** for computations and **routing data dependencies** ğŸ—ºï¸

---

## Compilation for CGRAs: Modulo Scheduling â±ï¸

*   A key technique for mapping loop kernels ğŸ”‘
*   A **software pipelining technique** ğŸŒ€
*   Exploits **instruction-level parallelism (ILP) among loop iterations** ğŸ”„
*   Pipelining consecutive iterations provides more parallelism and improves resource utilization ğŸ“ˆ
*   **Mapping has three parts:** (Refers to Fig 5c in source)
    *   **Prologue:** Executed once at start ğŸ
    *   **Steady-state kernel:** Repeated, includes operations from one or more iterations ğŸ”
    *   **Epilogue:** Executed once at end ğŸ
*   **Initiation Interval (II):** Schedule length of the steady-state kernel ğŸ“
    *   Number of cycles between initiating consecutive loop iterations ğŸ”¢
    *   Dominates execution time for loops with many iterations â³
    *   Mapping example shows II=2 (Fig 5c) 2ï¸âƒ£

---

## Compilation for CGRAs: Minimum II

*   The mapper calculates the **Minimum Initial Interval (MII)** ğŸ§®
*   MII is the **maximum** of:
    *   **Resource-minimal II:** Depends on number of PEs and DFG nodes (Cannot be less than ceil(DFG nodes / PEs))
    *   **Recurrence-minimal II:** Determined by dependencies across loop iterations (e.g., `a[i] = a[i-1] * b[i]`) ğŸ”„
*   Mapping algorithm starts with II = max(Resource MII, Recurrence MII) and increases II if scheduling fails ğŸ“ˆ

---

## Compilation for CGRAs: Modulo Routing Resource Graph (MRRG)

*   Proposed by Mei et al. (2003b) ğŸ“œ
*   Represents **resources and routing for a time-extended CGRA** â±ï¸ğŸ—ï¸
*   A directed graph **G_II** for a given II â†”ï¸
*   **Nodes:** Tuple (resource, cycle), where resource is a CGRA component (PE port, network, ALU, etc.) and cycle is time (0 to II-1) â³
*   **Edges:** Connection from resource m at cycle t to resource n at cycle t+1 â¡ï¸
*   **Wrapped-around edges:** From cycle II-1 back to cycle 0, representing the cyclical nature of configurations (Refers to Fig 6 in source) ğŸ”„
*   In modulo scheduling, occupying a node (resource, t) implies occupying (resource, t + k*II) for k>0 ğŸ”¢

---

## CGRA Mapping Approaches Overview ğŸ—ºï¸

*   Three broad classes:
    1.  **Heuristic Approaches:** Customized solutions, meta-heuristics ğŸ”
    2.  **Mathematical Optimization Techniques:** Formal methods â—
    3.  **Graph-Theory-Inspired Techniques:** Transform problem into graph formalisms

---

## Heuristic Approaches: Simulated Annealing ğŸ”¥

*   Problem-independent meta-heuristic â„ï¸
*   Used in **DRESC compiler** (Mei et al., 2003b) ğŸ› ï¸
*   Starts with an initial schedule (satisfying dependencies, possibly resource overuse) ğŸ
*   Iteratively reduces resource overuse via **simulated annealing** â™¨ï¸
*   Explores different **placement and routing** options ğŸ—ºï¸
*   **Cost function:** Based on total routing cost and resource consumption ğŸ’°
*   Can have **long convergence time** for large DFGs â³
*   Extensions handle register allocation (e.g., De Sutter et al., 2008; meeting graph)
*   Other works aimed at better cost functions (Hatanaka & Bagherzadeh, 2007; CGRA-ME, Chin et al., 2017) ğŸ¯

---

## Heuristic Approaches: Edge-Centric Modulo Scheduling â†”ï¸

*   Contrast to node-centric scheduling (DRESC) (Refers to Fig 7 in source)
*   **Primary objective: Routing efficiency** rather than operation assignment ğŸ¯
*   **Node-centric:** Places operations first based on heuristic routing cost, then routes edges (Fig 7b) ğŸ“
*   **Edge-centric (EMS):** Routing function contains placement ğŸ—ºï¸
    *   Placement decision made when routing information is discovered ğŸ”
    *   Picks an edge from a mapped node, starts routing ğŸ›£ï¸
    *   Router searches for empty slot for target operation, temporarily places it, recursively routes other edges (Fig 7c) ğŸ”„
*   Can find solutions **faster** and achieve **better quality** than node-centric âš¡
*   **Greedy nature:** Optimizes for a single edge, can fall into local minima
*   Requires efficient heuristics for assigning priorities ğŸ†

---

## Heuristic Approaches: Schedule, Place, and Route (SPR) ğŸ—“ï¸ğŸ“ğŸ›£ï¸

*   A mature mapping tool (Friedman et al., 2009) ğŸ› ï¸
*   Combines **VLIW-style scheduler** and **FPGA placement/routing algorithms** ğŸ¤
*   Three steps:
    1.  **Scheduling:** Ordering operations in time (Uses Iterative Modulo Scheduling (IMS)) â±ï¸
    2.  **Placement:** Assigning operations to FUs (Uses Simulated Annealing, inspired by VPR) ğŸ“
    3.  **Routing:** Mapping data signals using wires/registers (Uses PathFinder and QuickRoute) ğŸ›£ï¸
*   Extends IMS for CGRAs to support configurable interconnects and rescheduling with feedback ğŸ”„
*   Adapts FPGA algorithms (VPR, PathFinder) for CGRA specifics (resource multiplexing, fixed frequency) âš™ï¸

---

## Heuristic Approaches: List Scheduling ğŸ“

*   Adapted in Bansal et al. (2003) ğŸ› ï¸
*   **Priority-based heuristic:** Maps data-dependent operations onto spatially close PEs ğŸ“
*   Maintains PE list (topology traversal order) and operation list (scheduling priority, e.g., longest dependency path) ğŸ†
*   Maps highest priority operation to next available PE if valid route exists âœ…
*   **Cycle-by-cycle scheduling:** Schedules on each PE, increments cycle when PE list exhausted â±ï¸
*   **Limitation:** Does **not produce software pipelined schedules**, unable to exploit inter-iteration parallelism ğŸ”„

---

## Heuristic Approaches: Evolutionary Algorithm ğŸ§¬

*   Fast heuristic using a quantum-inspired evolutionary algorithm âš›ï¸
*   Uses list scheduling result as starting point ğŸ
*   **Q-Bit encoding:** Compactly represents potential mappings, enables fast exploration ğŸ”
*   Fitness function: Performance (inverse of total latency) â±ï¸
*   Limited evaluation on small kernels/CGRAs

---

## Heuristic Approaches: Machine Learning ğŸ¤–

*   **RLMap (Liu et al., 2018):** Reinforcement learning ğŸ®
    *   CGRA mapping as an RL agent problem ğŸ¤–
    *   Mapping state = image, action = swap operations on neighbor PEs
    *   Reward function based on cost (interconnect power, PE utilization)
*   **DFGNet (Yin et al., 2017a):** Convolutional Neural Network ğŸ§ 
    *   Dual-input NN for DFG (adjacency matrix) and CGRA state (matrix)
    *   Translates mapping to image-based classification ğŸ–¼ï¸
    *   **Issue:** Difficulty obtaining abundant training data
*   **LISA (Li et al., 2022):** Graph Neural Network
    *   **Portable framework** for diverse CGRAs ğŸ’
    *   GNN analyzes DFG to derive mapping labels (e.g., routing resource required, mapping distance) ğŸ·ï¸
    *   Provides a **global view** ğŸŒ
    *   For new accelerators, GNN retrained to adapt labels ğŸ”„

---

## Math. Optimization Techniques â—

*   Formal methods for CGRA mapping ğŸ“
*   **Integer Linear Programming (ILP):**
    *   Formalizes mapping as an ILP problem (Ahn et al., 2006; Chin & Anderson, 2018) ğŸ“œ
    *   ILP formulation includes all requirements and constraints (from DFG and MRRG) ğŸ“
    *   **Highly portable** (CGRA-ME project) ğŸ’
    *   **Scalability is a huge issue** â€“ only applicable to very simple kernels
    *   Effectiveness for all architectural features is unclear â“
*   **Boolean Satisfiability (SAT) Solvers:**
    *   Application mapping approach used by Wave Computing for their DPU
    *   Automatically compile dataflow graphs onto a huge CGRA (16,000 PEs)
    *   Innovative application of SAT to solve complex, irregular optimization
    *   Produces **high-quality results** comparable to hand-written assembly
    *   Efficiently utilizes PEs with rich features ğŸ’
    *   Requires **custom algorithms** for scalability and robustness ğŸ› ï¸
    *   Constraint-based approach also used for Silicon Hive ğŸ

---

## Graph-Theory-Inspired Techniques

*   Transform the CGRA mapping problem into **well-known graph-theoretic formulations** â†”ï¸
*   Leverage existing techniques to solve ğŸ› ï¸
*   Concepts used: Subgraph homeomorphism, Graph epimorphism, Graph minor, Compatibility graph, Graph drawing âœï¸

---

## Graph Theory Definitions (For context) ğŸ“š

*   **Directed Graph G = (V, E):** Set of vertices V and edges E â†”ï¸
*   **Graph Isomorphism:** Bijective function f: V -> V' such that edges are preserved. Graphs look the same. (Refers to Fig 8) ğŸ”„
*   **Graph Subdivision:** Replacing an edge (u, v) with two edges (u, w) and (w, v) by adding a new vertex w. (Refers to Fig 9) âœ‚ï¸
*   **Graph Homeomorphism:** Two graphs are homeomorphic if an isomorphism exists between their subdivisions. (Refers to Fig 10) ğŸ 
*   **Induced Subgraph:** Subgraph formed by a subset of vertices U and all edges from the original graph connecting vertices within U. ğŸ§©

---

## Graph-Theory: Subgraph Homeomorphism ğŸ 

*   **Definition:** Homeomorphism from an induced subgraph Gâ†“U of G to G' ğŸ“–
*   Mapping DFG (G) to MRRG (H_II): Map DFG nodes to MRRG nodes (PEs at certain times) â±ï¸
*   DFG edge (u, v) maps to a **path** from f(u) to f(v) in MRRG ğŸ›£ï¸
*   This matches subgraph homeomorphism: the path in MRRG is a "subdivision" of the DFG edge (Refers to Fig 11) âœ‚ï¸
    *   Routing nodes (R) are added via edge subdivision (Fig 11c) â•
*   Adopted in Tuhin & Norvell (2008), Alle et al. (2008), Brenner et al. (2009) ğŸ“œ
*   **Limitation:** Requires edge mappings (paths) to be **node disjoint** (except endpoints) or edge disjoint ğŸš«
    *   Excludes sharing routing nodes (multi-net), potentially wasting routing resources ğŸ’¸

---

## Graph-Theory: Graph Epimorphism

*   Based on **Graph Homomorphism:** Function f: V -> V' such that (u,v) in E => (f(u),f(v)) in E'. Maps adjacent vertices to adjacent vertices. Can be from bigger to smaller graph. â†”ï¸
*   **Graph Epimorphism:** Surjective function f: V -> V' (both vertices and edges)
    *   Adjacent vertices in G map to adjacent vertices in G' â†”ï¸
    *   For every edge in G', there's a corresponding edge in G ğŸ”—
*   **EPIMap (Hamzeh et al., 2012):** Formalizes CGRA mapping as epimorphism + **recomputation** ğŸ› ï¸
    *   **Recomputation:** Same operation can be performed on multiple PEs for better routing ğŸ”„
    *   DFG G is morphed into G' (adding routing/recomputation nodes) â•
    *   Finds **maximal common subgraph (MCS)** between G' and MRRG H ğŸ”
    *   If MCS isomorphic to G', valid mapping found âœ…
*   Can generate **better scheduling results** compared to EMS (e.g., Fig 12 shows II=2 with recomputation vs. II=3 without) (Refers to Fig 12) ğŸ“ˆ

---

## Graph-Theory: Graph Minor

*   **Definition:** Undirected graph G is a minor of G' if G is isomorphic to a graph obtained by edge contractions on a subgraph of G' âœ‚ï¸
    *   **Edge contraction:** Removes edge, merges connecting vertices ğŸ”—
    *   Adapted for directed graphs for CGRA mapping (Chen & Mitra, 2014) â†”ï¸
*   Test if DFG is a minor of MRRG âœ…
*   Edges to be contracted represent routing paths in MRRG ğŸ›£ï¸
*   Mapping algorithm inspired by tree search ğŸŒ³
*   **Naturally allows for route sharing**, unlike subgraph homeomorphism (Refers to Fig 13) ğŸ¤
    *   Fig 13 shows reduced routing nodes (shared) compared to homeomorphism â–

---

## Graph-Theory: Compatibility Graph

*   REGIMap, Hamzeh et al., 2013
*   Formulation for mapping + using registers to minimize II â±ï¸
*   Partitions problem: scheduling + integrated placement/register allocation ğŸ§©
*   **Compatibility graph:** Subgraph of DFG x MRRG product âœ–ï¸
*   Vertices = (operation, resource) pair (possible mapping pairs) â†”ï¸
*   Edges = compatibility of two mapping pairs ğŸ¤
*   Mapping problem reduced to finding the **largest clique** in the compatibility graph under register constraints ğŸ”
*   Uses an efficient constructive heuristic ğŸ› ï¸

---

## Graph-Theory: Graph Drawing

*   SPKM, Yoon et al., 2009
*   Adopts split and push technique (Di Battista et al., 1998) for planar graph drawing âœï¸
*   Focuses on **spatial mappings** ğŸ—ºï¸
*   Starts with all DFG nodes in one group (represents one PE) 1ï¸âƒ£
*   Group is split, nodes pushed to new group â—
*   Splitting continues until each group has one node (one-to-one mapping to planar CGRA graph) ğŸ¯

---

## Compilation: Table Summary (Optional - for detail) ğŸ“‹

*   Show Table 1 from the source
*   Lists notable works using graph theory concepts:
    *   Alle et al. (Homeomorphism, Greedy, DFG substructures) ğŸ 
    *   EpiMap (Epimorphism, Heuristic, Recomputation)
    *   Graph Minor (Graph Minor, Tree search, Route sharing)
    *   RegiMap (Compatibility graph, Max clique, Route sharing/Recomputation) ğŸ¤
    *   SPKM (Graph Drawing, Split and push, Heterogeneous support) âœï¸

---

# Other Compilation-Related Issues

---

## Data Access Challenges ğŸ§ 

*   Previous computation mapping often ignores **data placement and CPU-CGRA communication** ğŸš«
*   Assumptions often made: data already in local memory, all PEs access all data memories (infinite bandwidth) â™¾ï¸
*   **Reality:**
    *   CGRA local memory (SPM) is **non-uniform access**
    *   Only a **subset of PEs access memory banks** with limited ports (Refers to Fig 14 in source) ğŸšª
    *   Memory limitations can cause **overall performance degradation** despite high compute utilization
*   Compiler must be **memory-aware** ğŸ§ 
    *   Mapping needs awareness of data placement to correctly place load/store operations ğŸ“
    *   Data placement and CGRA mapping are **interdependent** â†”ï¸
    *   Host CPU manages data movement via DMA based on compiler's data placement ğŸ—ï¸

---

## Memory-Aware Compilation ğŸ§ 

*   **Goals:**
    *   Place data without under-utilizing banks ğŸ¦
    *   Consider limited PE-memory connections ğŸ”—
    *   Prevent memory access conflicts âš”ï¸
    *   Maximize data reuse ğŸ”„

---

## Memory-Aware Compilation ğŸ§ 

*   Approaches:
    *   Kim et al. (2010) heuristic: Considers memory params, minimizes duplicate arrays, balances bank utilization, balances computation/transfer time âš–ï¸
    *   Resolving access conflicts:
        *   Can be solved by **data duplication** or **hardware queues** (higher cost) ğŸ’°
        *   Better: Compiler **partitions data** into banks to avoid conflicts ğŸ§©
        *   Kim et al. (2010) maps operations/data to avoid conflicts, uses array clustering and conflict-free scheduling ğŸ¯
        *   Yin et al. (2016a, 2017b) propose conflict-free mapping, joint modulo scheduling and memory partitioning ğŸ§©
        *   Wang et al. (2013): Memory partitioning scheme for multi-dimensional arrays using linear transformation ğŸ“
    *   Memory as a routing resource (Yin et al., 2015): Routing some dependencies through memory can improve performance, divides mapping into subproblems ğŸ§©

---

## Memory Address Generation ğŸ 

*   Significant portion of loop kernel instructions (20-80%) for address generation
*   **Overhead** in CGRA âš–ï¸
*   Solution: **Offload address generation** to specialized units ğŸš€
*   Advocacy for **decoupled access-execute CGRAs**: Memory address generation separated from main computation execution â†”ï¸
    *   Nowatzki et al. (2017): Stream-dataflow, complex memory hierarchy, stream-based interface ğŸŒŠ
    *   Wijerathne et al. (2019): Software and hardware support for conflict-free access âœ…

---

## Nested Loop Mapping ğŸ”„

*   Most approaches focus on single innermost loops 1ï¸âƒ£
*   Motivation to map **beyond innermost loop**:
    *   More parallelism available ğŸ¤
    *   Avoids host CPU overheads from multiple invocations for imperfect nested loops (pipeline filling/draining, initialization) â³

---

## Nested Loop Mapping Approaches ğŸ—ºï¸

*   **Polyhedral-Model-Based (Liu et al., 2013):**
    *   Robust framework for loop transformation ğŸ—ï¸
    *   Maps innermost two loops 2ï¸âƒ£
    *   Transforms 2D nested loops to parallelogram iteration domain ğŸ“
    *   Tiles parallelogram, maps operators in each tile to CGRA ğŸ§©
    *   Objective: Reduce execution time by determining tile parameters (uses genetic algorithm) ğŸ§¬
*   **Loop Flattening Based (Lee et al., 2014):**
    *   Converts imperfect nests into a single nested loop for single invocation 1ï¸âƒ£
    *   Overhead: Increased code size ğŸ“ˆ
    *   Combines **loop fission** with flattening âœ‚ï¸
    *   Introduces specialized PE operations: nested iterators, extended accumulator, periodic store âš™ï¸

---

## Nested Loop Mapping Approaches ğŸ—ºï¸

*   **Systolic-Mapping-Based (HiMap, Wijerathne et al., 2021a,b):**
    *   Hierarchical mapping for **regular multi-dimensional kernels**
    *   Uses systolic mapping as intermediate abstraction ğŸ—ï¸
    *   Iteration mapped to virtual PE cluster based on space-time matrix â±ï¸
    *   Maps operations in each iteration to physical PEs ğŸ—ï¸
    *   Generates detailed mapping for **unique iterations**, replicates for final mapping ğŸ”„
    *   Fast and scalable for regular kernels âš¡

---

## Nested Loop Mapping under Limited Config Memory ğŸ’¾

*   Configuration memory size is a constraint ğŸ“
*   Mapping two innermost loops can be limited (Lee et al., 2014 vs. Yin et al., 2016b) 2ï¸âƒ£
*   Architectural improvements: **Configuration memory as a cache** (Cao et al., 2017; Jafri et al., 2015) ğŸ’¾
    *   Stores most recently accessed loop nests ğŸ”„
    *   Dynamic caching improves performance by accelerating more segments and minimizing data transfer âš¡
*   **DNestMap (Karunaratne et al., 2018):**
    *   Partitioning and mapping tool ğŸ› ï¸
    *   Extracts most beneficial code segments from deeply nested loops ğŸ”
    *   Statically caches them via **spatio-temporal partitioning** â±ï¸

---

## Application-Level Mapping ğŸ“±

*   An application has multiple kernels (sequential, single loop, nested loops, combinations) ğŸ”„
*   CGRAs can accelerate various kernels by reconfiguring ğŸ”„
*   ASICs target specific kernels, FPGAs map spatially (limited by area, slow reconfiguration for frequent changes) ğŸ¢
*   **CGRA advantage:** Spatio-temporal mapping allows frequent configuration changes per cycle â±ï¸
*   **Partitioning between CPU and CGRA:**
    *   Some kernels benefit more from CGRA than others âš–ï¸
    *   Limited on-chip memory may require main memory for intermediate data ğŸ’¾
    *   Lee et al. (2015): Profiles kernels, uses **ILP to select kernels** for CGRA vs. CPU â—
    *   Maximizes CGRA utilization, reduces data transfer ğŸ“ˆ
    *   Work focused on small CGRA, didn't explore concurrent kernel execution ğŸ”„

---

## Synchronous Dataflow (SDF) ğŸŒŠ

*   **SDF:** A suitable representation for application-level mapping ğŸ—ºï¸
*   Has **actors** that consume/produce **tokens** (Refers to Fig 15 in source) ğŸ­
*   Actor can be sequential code, loop, loop nest, etc. ğŸ”„
*   Needs a **schedule to orchestrate actors** and balance execution while satisfying dependencies â±ï¸
    *   Bounded-buffer schedules (e.g., A(BC2)2, AB2C4)
*   **Spatial vs. Spatio-temporal mapping for SDF:** (Refers to Fig 16 in source)
    *   FPGA maps actors spatially, occupying regions throughout (Fig 16a) - hard to balance execution with spatial-only âš–ï¸
    *   CGRA spatio-temporal mapping provides a **3D space** for scheduling (Fig 16b) - more flexibility ğŸ®
*   **ChordMap (Li et al., 2021):**
    *   Maps SDF onto CGRA for high throughput ğŸš€
    *   Uses **divide-and-conquer** to partition SDF and CGRA âœ‚ï¸
    *   Maps sub-SDFs onto sub-CGRAs iteratively ğŸ”„
    *   Exploits parallelism: inside actors (ILP), among actors/instances, pipeline parallelism among sub-SDFs ğŸ¤

---

## Handling Control Flow ğŸ›ï¸

*   **Statically scheduled CGRAs:** Rely on **predication** for loops with complex control flow ğŸ“
    *   Translates control flow to dataflow instructions â†”ï¸
    *   Maps both paths of a branch â†”ï¸
    *   Only instructions from taken path execute âœ…
    *   Leads to **resource underutilization** (static allocation of unused resources)
*   **4D-CGRA (Karunaratne et al., 2019):**
    *   New execution paradigm for control divergence ğŸ”€
    *   **Semi-triggered execution model:** Hybrid of sequential and triggered âš¡
    *   Compiler places multiple **shards** (portion of a basic block) from mutually exclusive paths on a PE ğŸ§©
    *   Triggers a **specific shard at runtime** â±ï¸

---

## Scalable CGRA Mapping ğŸ“ˆ

*   **Scalability challenge:** Most approaches fail to generate high-quality mappings in acceptable time for larger CGRAs and complex kernels â³
    *   Placement and routing become difficult ğŸ—ºï¸
    *   Many mappers evaluated only on small benchmarks/CGRAs (Refers to Table 2 in source)
    *   SPR (Friedman et al., 2009) is one of the more scalable evaluated on larger kernels/CGRA ğŸ—ï¸
*   **Panorama (Wijerathne et al., 2022b):**
    *   Fast and scalable mapper for complex DFGs onto larger CGRAs âš¡
    *   **Divide-and-conquer approach** âœ‚ï¸
    *   Portable solution, can combine with low-level mappers ğŸ’
    *   **High-level mapping:** Finds DFG node clusters, maps clusters to CGRA PE clusters ğŸ§©
    *   High-level mapping guides lower-level mapping, reduces complexity
*   **HiMap:** Also fast and scalable, but specialized for regular, highly parallel kernels (as discussed earlier) âš¡
*   Similar multi-level parallelism exploration seen in FPGAs ğŸ—ï¸

---

## Conclusion ğŸ

*   **CGRAs:** Emerging general-purpose spatial accelerators ğŸš€
*   Deliver **high performance, energy efficiency, and flexibility** across application domains âš¡
*   Significant architectural and compilation innovations over two decades have helped realize their potential ğŸ•°ï¸ğŸ’¡
*   Compilation is **key** due to the flexibility and need for spatio-temporal mapping ğŸ”‘ğŸ—ºï¸
*   Various mapping approaches exist (heuristics, formal methods, graph theory, ML) with different trade-offs in quality, time, and scalability ğŸ”„ğŸ“Š

---

## Future Work and Challenges ğŸŒŸ

*   Remaining challenges and opportunities:
    *   **Scalability** for more complex applications ğŸ“ˆ
    *   Improved **Memory management** ğŸ’¾
    *   Runtime power management (not detailed in these excerpts) ğŸ”‹
    *   Specializations for important and emerging application domains ğŸ—ï¸ğŸ“ˆ
*   Active area of research and industry interest ğŸ“šğŸ”¬

---

count: false
class: nord-dark, middle, center

.pull-left[

# Q&A ğŸ¤

] .pull-right[

![Discussion](figs/questions-and-answers.svg)

]
