<!doctype html>
<html>
  <head>
    <title>Network Optimization: Quick Start</title>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"
    />
    <link rel="stylesheet" type="text/css" href="../katex/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../css/spaces.css" />
    <link rel="stylesheet" type="text/css" href="../css/slides.css" />
    <link rel="stylesheet" type="text/css" href="../css/nord-dark.css" />
    <link rel="stylesheet" type="text/css" href="../css/nord-light.css" />
    <link rel="stylesheet" type="text/css" href="../css/font-nord.css" />
    <link rel="stylesheet" type="text/css" href="../css/bg-nord.css" />
    <link rel="stylesheet" type="text/css" href="../css/style.css" />
  </head>
  <body>
    <textarea id="source">

layout: true
class: typo, typo-selection

---

class: nord-dark, middle, center

# Network Optimization: Quick Start ‚ö°

@luk036 üë®‚Äçüíª

2025-06-17 üìÖ

---

### Abstract üìù

This lecture serves as an introductory guide to the algorithms used to solve network optimization problems. It covers several important concepts and techniques for both beginners and advanced users. The lecture begins by explaining how to explore the locality and associativity of a network, solve discrete optimization problems, and gain insight into critical parts of the network's cut and cycle. It then delves into basic concepts such as nodes, edges, orientation, the node-edge incidence matrix, and the boundary operator. It then explains the flow and potential of a network. It also examines feasibility problems and provides examples such as clock skew scheduling and delay padding. The lecture concludes with guidelines for algorithm developers and average users, suggesting special handling of multi-edges and techniques for finding negative cycles and cuts. Overall, the lecture provides a quick start guide to network optimization, covering important algorithms and concepts needed to tackle such problems.

---

class: nord-light, middle, center

### üé¨ Introduction

---

### Why and why not ‚ùì

.pull-left[

Why? ‚úîÔ∏è

-   üëç Algorithms are available for common network problems (Python: `networkx`, `digraphx`, C++: Boost Graph Library (BGL)):
    -   Explore the locality of network.
-   üëç Be able to solve discrete problems optimally (e.g.¬†matching/assignment problems)

-   üëç Bonus: gives you insight into the most critical parts of the network (critical cut/cycle)

]
.pull-right[

Why not? ‚úñÔ∏è

-   üëé The theory is hard to understand.

-   üëé Algorithms are hard to understand (some algorithms do not allow
       users to have an input flow in reverse directions,
       but create edges internally for the reverse flows).

-   üëé There are too many algorithms available.
       You have to choose them wisely.

]

---

### Flow and Potential ‚öñÔ∏è

.pull-left[

-   Cut ‚úÇÔ∏è
-   Current ‚ö°
-   Flow ${\color{green}x}$ üíß
-   Sum of ${\color{green}x}_{ij}$ around a node = 0 üîÑ

    ![flow](media/flow.svg)

]
.pull-right[

-   Cycle/Path üîÑ
-   Voltage üîã
-   Tension ${\color{blue}y}$ üèóÔ∏è
-   Sum of ${\color{blue}y}_{ij}$ around a cycle = 0 üîÑ

    ![potential](media/potential.svg)

]

---

### If you don't know more... ü§î

-   For the min-cost linear flow problem, the best guess is to use the "network simplex algorithm".

-   For the min-cost linear potential problem: formulate it as a dual (flow) problem. üîÑ

-   For the parametric potential problem (single parameter), the best guess is to use Howard's algorithm. ‚è±Ô∏è

-   All these algorithms are based on the idea of finding "negative cycle". ‚ûñ

-   You can apply the same principle to the nonlinear problems. üîÑ

---

### For dual problems... üîÑ

-   Dual problems can be solved by applying the same principle. üîÑ

-   Finding negative cycles is replaced by finding a negative "cuts", which is more difficult... ‚úÇÔ∏è

-   ...unless your network is a planar graph.

---

### Guidelines for the average users üë®üíª

-   Look for specialized algorithms for specialized problems.
    For example, for bipartite maximum cardinality matching,
    use the Hopcroft-Karp matching algorithm. ü§ù

-   Avoid creating edges with infinite costs. Delete them or reformulate your problem. ‚ôæÔ∏è

---

### Guidelines for algorithm developers üë©üíª

-   Make "negative cycles" as orthogonal to each other as possible. ‚ûñ

-   Reuse previous solutions as a new starting point for finding negative cycles. üîÑ

---

class: nord-light, middle, center

üí° Essential Concepts
--------------------

---

### Basic elements of a network üåê

- Definition (network)

  A *network* is a collection of finite-dimensional vector spaces, which includes *nodes* and *edges*/*arcs*:

  - ${\color{salmon}V} = \{{\color{brown}v_1}, {\color{brown}v_2}, \cdots, {\color{brown}v_N} \}$, where $|{\color{salmon}V}| = N$
  - ${\color{lime}E} = \{{\color{darkgreen}e_1}, {\color{darkgreen}e_2}, {\color{darkgreen}e_3}, \cdots, {\color{darkgreen}e_M} \}$, where $|{\color{lime}E}| = M$

  which satisfies 2 requirements:

  1. The boundary of each edge is comprised of the union of nodes
  2. The intersection of any edges is either empty or the boundary node of both edges.

---

### Network üåê

-   By this definition, a network can contain self-loops and multi-edges. üîÑ

-   A *graph* structure encodes the neighborhood information of nodes and edges.

-   Note that Python's NetworkX requires special handling of multi-edges. üêç

-   The most efficient graph representation is an adjacency list. üìù

-   The concept of a graph can be generalized to *complex*: node, edge, face... üß©

#### Types of graphs

Bipartite graphs, trees, planar graphs, st-graphs, complete graphs.

---

### Orientation üß≠

.pull-left[

An *orientation* of an edge is an ordering of its boundary node $(s, t)$, where
-   $s$ is called a source/initial node
-   $t$ is called a target/terminal node

üëâ Note: orientation != direction

#### Coherent

Two orientations to be the same is called *coherent*

]
.pull-right[

![stokes](media/orientation.png)

]

---

### Node-edge Incidence Matrix

- Definition (Incidence Matrix)

  An $N \times M$ matrix ${\color{blue} A^\mathsf{T} }$ is a node-edge incidence matrix with entries:

  $${\color{green} A}(i,j) =
  \begin{cases}
   +1 & \text{if ${\color{darkgreen}e_i}$ is coherent with the orientation of node ${\color{brown}v_j}$,} \\
   -1 & \text{if ${\color{darkgreen}e_i}$ is not coherent with the orientation of node ${\color{brown}v_j}$,} \\
    0 & \text{otherwise.}
  \end{cases} $$

- Example

  $${\color{blue} A^\mathsf{T} } =
  \begin{bmatrix}
  0 & -1 & 1 & 1 & 0 \\
  1 & 1 & 0 & -1 & -1 \\
  -1 & 0 & -1 & 0 & 1
  \end{bmatrix}$$

---

### Chain ‚õìÔ∏è

- Definition (Chain $\tau$)

  An edge/node *chain* $\tau$ is an $M$/$N$-tuple of scalar that assigns a coefficient to each edge/node,where $M$/$N$ is the number of distinct edges/nodes in the network.

- Remark (II)

  A chain may be viewed as an (oriented) indicator vector representing a set of edges/nodes.

- Example (II)

  $[0, 0, 1, 1, 1]$, $[0, 0, 1, -1, 1]$

---

### Discrete Boundary Operator ‚úÇÔ∏è

- Definition (Boundary operator)

  The *boundary* operator ${\color{blue}\partial} = {\color{blue}A^\mathsf{T} }$.

- Definition (Cycle)

  A chain is said to be a *cycle* if it is in the null-space of the boundary operator, i.e. ${\color{blue}A^\mathsf{T} } \tau = 0$.

- Definition (Boundary)

  A chain $\beta$ is said to be a *boundary* of $\tau$ if it is in the range of the boundary operator.

---

### Co-boundary Operator ${\color{green}\mathrm{d} }$ üîÑ

- Definition (Co-boundary operator)

  The *co-boundary* (or *differential*) operator
${\color{green}\mathrm{d} } = {\color{blue}\partial}^* = ({\color{blue}A^\mathsf{T} })^* = {\color{green}A}$

- üëâ Note

  Null-space of ${\color{green}A}$ is \#components of a graph

---

### Discrete Stokes' Theorem üìú

-   Let $${\color{green}\tau_i} = \begin{cases}
        1 & \mathrm{if}\ {\color{darkgreen}e_i} \in {\color{lime} S}, \\
        0 & \mathrm{otherwise.}
      \end{cases}$$
-   Conventional (integration):
    $${\color{purple}\int}_{\color{lime}S} {\color{green}\mathrm d} \tilde{\color{firebrick}\omega} = {\color{purple}\oint}_{\color{blue}\partial \color{lime}S} \tilde{\color{firebrick}\omega}$$
-   Discrete (pairing):
    $${\color{purple}{[} \color{green}\tau}, {\color{green}A}{\color{firebrick}\omega}{\color{purple}]} = {\color{purple}[ \color{blue}A^\mathsf{T} \color{green}\tau}, {\color{firebrick}\omega}{\color{purple}]}$$

---

### Fundamental Theorem of Calculus

- Conventional (integration): $\int_a^b f(t) dt = F(b) - F(a)$

- Discrete (pairing): $[{\color{green}\tau_1}, {\color{green} A} {\color{firebrick}c^0}] = [{\color{blue} A^\mathsf{T} }{\color{green}\tau_1}, {\color{firebrick}c^0}]$

  ![stokes](media/stokes.svg)

---

### Divergence and Flow üíß

- Definition (Divergence)

  $\text{div}\, {\color{green}x} = {\color{blue} A^\mathsf{T} } {\color{green}x}$

- Definition (Flow)

  ${\color{green}x}$ is called a *flow* if $\sum \text{div}\, {\color{green}x} = 0$, where all negative entries of (div ${\color{green}x}$) are called *sources* and positive entries are called *sinks*.

- Definition (Circulation)

  A network is called a *circulation* if there is no source or sink. In other words, $\text{div}\, {\color{green}x} = 0$

---

### Tension and Potential ‚ö°

- Definition (Tension)

  A tension (in co-domain) ${\color{blue}y}$ is a *differential* of a *potential* ${\color{firebrick}u}$, i.e. ${\color{blue}y}= {\color{green} A} {\color{firebrick}u}$.

- Theorem (Tellgen's)

  Flow and tension are bi-orthogonal (isomorphic).

- Proof

  $0 = [{\color{blue} A^\mathsf{T} } {\color{green}x}, {\color{firebrick}u}] = ({\color{blue} A^\mathsf{T} } {\color{green}x})^\mathsf{T} {\color{firebrick}u} = {\color{green}x}^\mathsf{T} ({\color{green} A} {\color{firebrick}u}) = {\color{green}x}^\mathsf{T} {\color{blue}y}$

---

### Path üõ£Ô∏è

A path indicator vector ${\color{green}\tau}$ of ${\color{lime}P}$ that $${\color{green}\tau_i} =
    \begin{cases}
       1 & \mathrm{if}\ {\color{darkgreen}e_i} \in {\color{lime}P}, \\
       0 & \mathrm{otherwise.}
    \end{cases}$$

- Theorem

  [total tension ${\color{blue}y}$ on ${\color{lime}P}$] = [total potential on the boundary of ${\color{lime}P}$].

- Proof

  ${\color{blue}y}^\mathsf{T} {\color{green}\tau} = ({\color{green} A} {\color{firebrick}u})^\mathsf{T} {\color{green}\tau} = {\color{firebrick}u}^\mathsf{T}({\color{blue} A^\mathsf{T} } {\color{green}\tau}) = {\color{firebrick}u}^\mathsf{T}({\color{blue} \partial} {\color{lime}P})$.

---

### Cut ‚úÇÔ∏è

Two node sets ${\color{salmon}S}$ and ${\color{salmon}S}'$ (the complement of ${\color{salmon}S}$, i.e. ${\color{salmon}V} - {\color{salmon}S}$).
A cut ${\color{steelblue}Q}$ is an edge set, denoted by $[{\color{salmon}S}, {\color{salmon}S}']^-$.
A cut indicator vector ${\color{blue}q}$ (oriented) of ${\color{steelblue}Q}$ is defined as ${\color{green} A} {\color{firebrick}c}$ where $${\color{firebrick}c_i} =
  \begin{cases}
    1 & \text{if } {\color{brown}v_i} \in {\color{salmon}S} \,, \\
    0 & \text{otherwise}\,.
  \end{cases}
$$

- Theorem (Stokes' theorem!)

  [Total divergence of ${\color{green}x}$ on ${\color{lime}S}$] = [total ${\color{green}x}$ across ${\color{steelblue}Q}$].

- Proof

  $(\text{div}\,{\color{green}x})^\mathsf{T} {\color{firebrick}c} = ({\color{blue} A^\mathsf{T} } {\color{green}x})^\mathsf{T} {\color{firebrick}c} = {\color{green}x}^\mathsf{T} ({\color{green} A} {\color{firebrick}c}) = {\color{green}x}^\mathsf{T} {\color{blue}q}$.

---

### Examples

![cut](media/cut.svg)

---

class: nord-light, middle, center

Feasibility Problems ‚úÖ
--------------------

---

### Feasible Flow/Potential Problem ‚öñÔ∏è

.pull-left[

Feasible Flow Problem üíß

-   Find a flow ${\color{green}x}$ such that: $$\begin{array}{ll}
      {\color{green}c^-} \leq {\color{green}x} \leq {\color{green}c^+}, \\
      {\color{blue} A^\mathsf{T} } {\color{green}x} = {\color{firebrick}b}, {\color{firebrick}b}({\color{salmon}V}) = 0.
      \end{array}$$

-   Can be solved using:

    -   Painted network algorithm

    -   If no feasible solution, return a "negative cut". ‚úÇÔ∏è

]
.pull-right[

Feasible Potential Problem: ‚ö°

-   Find a potential ${\color{firebrick}u}$ such that: $$\begin{array}{ll}
      {\color{blue}d^-} \leq {\color{blue}y} \leq {\color{blue}d^+} \\
      {\color{green}A}  \cdot {\color{firebrick}u} = {\color{blue}y}.
      \end{array}$$

-   Can be solved using:

    -   Bellman-Ford algorithm

    -   If no feasible solution, return a "negative cycle". ‚ûñ

]

---

### Examples

.pull-left[

Genome-scale reaction (primal) üß¨

-   ${\color{green} A}$: Stoichiometric matrix

-   ${\color{green}x}$: reactions between metabolites/proteins

-   ${\color{green}c^-} \leq {\color{green}x} \leq {\color{green}c^+}$: constraints on reaction rates

]
.pull-right[

Timing constraints (co-domain) ‚è±Ô∏è

-   ${\color{blue} A^\mathsf{T} }$: incidence matrix of timing constraint graph

-   ${\color{firebrick}u}$: arrival time of clock

-   ${\color{blue}y}$: clock skew

-   ${\color{blue}d^-} \leq {\color{blue}y} \leq {\color{blue}d^+}$: setup- and hold-time
    constraints

]

---

### Feasibility Flow Problem üíß

- Theorem (feasibility flow)

  The problem has a feasible solution if and only if ${\color{firebrick}b}({\color{salmon}S}) \leq {\color{green}c^+}({\color{steelblue}Q})$ for all cuts ${\color{steelblue}Q} = [{\color{salmon}S},{\color{salmon}S}']$ where ${\color{green}c^+}({\color{steelblue}Q})$ = upper capacity [1, p.¬†56].

---

### Proof (if-part) ‚úÖ

Let ${\color{blue}q} = {\color{green} A} \cdot {\color{firebrick}k}$ be a cut vector (oriented) of ${\color{steelblue}Q}$. Then

-   ${\color{green}c^-} \leq {\color{green}x} \leq {\color{green}c^+}$

--

-   ${\color{blue}q}^\mathsf{T} {\color{green}x} \leq {\color{green}c^+}({\color{steelblue}Q})$

--

-   $({\color{green} A} \cdot {\color{firebrick}k})^\mathsf{T} {\color{green}x} \leq {\color{green}c^+}({\color{steelblue}Q})$

--

-   ${\color{firebrick}k}^\mathsf{T} {\color{blue} A^\mathsf{T} } {\color{green}x} \leq {\color{green}c^+}({\color{steelblue}Q})$

--

-   ${\color{firebrick}k}^\mathsf{T} {\color{firebrick}b} \leq {\color{green}c^+}({\color{steelblue}Q})$

--

-   ${\color{firebrick}b}({\color{salmon}S}) \leq {\color{green}c^+}({\color{steelblue}Q})$

---

### Feasibility Potential Problem ‚ö°

- Theorem (feasibility potential)

  The problem has a feasible solution if and only if ${\color{blue}d^+}({\color{lime}P}) \geq 0$ for all cycles ${\color{lime}P}$ where ${\color{blue}d^+}({\color{lime}P})$ = upper span [1, p. ??].

---

### Proof (if-part) ‚úÖ

Let ${\color{green}\tau}$ be a path indicator vector (oriented) of ${\color{lime}P}$. Then

-   ${\color{blue}d^-} \leq {\color{blue}y} \leq {\color{blue}d^+}$

--

-   ${\color{green}\tau}^\mathsf{T} {\color{blue}y} \leq {\color{blue}d^+}({\color{lime}P})$

--

-   ${\color{green}\tau}^\mathsf{T} ({\color{green} A} \cdot {\color{firebrick}u}) \leq {\color{blue}d^+}({\color{lime}P})$

--

-   $({\color{blue} A^\mathsf{T} } {\color{green}\tau})^\mathsf{T} {\color{firebrick}u} \leq {\color{blue}d^+}({\color{lime}P})$

--

-   $({\color{blue} \partial} {\color{lime}P})^\mathsf{T} {\color{firebrick}u} \leq {\color{blue}d^+}({\color{lime}P})$

--

-   $0 \leq {\color{blue}d^+}({\color{lime}P})$

---

### Remarks

-   The only-if part of the proof is constructive.
    It can be done by constructing an algorithm to obtain the feasible solution.

-   ${\color{blue}d^+}$ could be $\infty$ or zero, etc. ‚ôæÔ∏è

-   ${\color{blue}d^-}$ could be $-\infty$ or zero, etc. ‚ôæÔ∏è

-   ${\color{green}c^+}$ could be $\infty$ or zero, etc. ‚ôæÔ∏è

-   ${\color{green}c^-}$ could be $-\infty$ or zero, etc. ‚ôæÔ∏è

**Note**: most tools require that ${\color{green}c^-}$ must be zero such that the solution flow ${\color{green}x}$ is always positive.

---

### Convert to the elementary problem üîÑ

.pull-left[

-   By splitting every edge into two, the feasibility flow problem can reduce to an elementary one:
    -   Find a flow ${\color{green}x}$ such that
        $$\begin{array}{ll}
          {\color{green}c} \leq {\color{green}x}, \\
          {\color{blue}A_1^\mathsf{T} } {\color{green}x} = {\color{firebrick}b_1}, \\
          {\color{firebrick}b_1}({\color{salmon}V_1}) = 0.
        \end{array}$$

]
.pull-right[

Original:

.mermaid[
<pre>
graph LR
    A(("i")) -- "[c-, c+]" --> B(("j"))
</pre>
]

Modified:

.mermaid[
<pre>
graph LR
    A(("i")) -- "c-" --> B(("k"))
    B -. "- c+" .-> C(("j"))

    B:::Rose
    classDef Rose stroke-width:1px, stroke-dasharray:none, stroke:#FF5978, fill:#FFDFE5, color:#8E2236
</pre>
]

]

---

### Convert to the elementary problem üîÑ

.pull-left[

-   By adding a reverse edge for every edge, the feasibility potential problem can reduce to an elementary one:

    -   Find a potential ${\color{firebrick}u}$ such that
        $$\begin{array}{ll}
          {\color{blue}y_2} \leq {\color{blue}d}, \\
          {\color{green}A_2} {\color{firebrick}u} = {\color{blue}y_2}
        \end{array}$$

        where ${\color{green}A_2}$ is the incident matrix of the modified network.

]
.pull-right[

Original:

.mermaid[
<pre>
graph LR
    A(("i")) -- "[d-, d+]" --> B(("j"))
</pre>
]

Modified:

.mermaid[
<pre>
graph LR
    A(("i")) -- "d+" --> B(("j"))
    A -. "- d-" .-> B(("j"))
</pre>
]

]

---

### Basic Bellman-Ford Algorithm ‚è±Ô∏è

.font-sm.mb-xs[

```matlab
function BellmanFord(list vertices, list edges, vertex source)
   // Step 1: initialize graph
   for each vertex i in vertices:
       if i is source then u[i] := 0
       else u[i] := inf
       predecessor[i] := null

   // Step 2: relax edges repeatedly
   for i from 1 to size(vertices)-1:
       for each edge (i, j) with weight d in edges:
           if u[j] > u[i] + d[i,j]:
               u[j] := u[i] + d[i,j]
               predecessor[j] := i

   // Step 3: check for negative-weight cycles
   for each edge (i, j) with weight d in edges:
       if u[j] > u[i] + d[i,j]:
           error "Graph contains a negative-weight cycle"
   return u[], predecessor[]
```

]

---

.font-sm.mb-xs[

```python
def _neg_cycle_relaxation(G, pred, dist, source, weight):
    G_succ = G.succ if G.is_directed() else G.adj
    inf = float('inf')
    n = len(G)
    count = {}
    q = deque(source)
    in_q = set(source)
    while q:
        u = q.popleft()
        in_q.remove(u)
        if pred[u] not in in_q:
            dist_u = dist[u]
            for v, e in G_succ[u].items():
                dist_v = dist_u + get_weight(e)
                 if dist_v < dist.get(v, inf):
                    if v not in in_q:
                        q.append(v)
                        in_q.add(v)
                        count_v = count.get(v, 0) + 1
                        if count_v == n:
                            return v
                        count[v] = count_v
                    dist[v] = dist_v
                    pred[v] = u
    return None
```

]

---

### Example 1 : Clock skew scheduling ‚è∞

-   Goal: intentionally assign an arrival time $u_i$ to each register
    so that the setup and hold time constraints are satisfied.
-   Note: the clock skew ${\color{blue}s}_{ij} = {\color{firebrick}u_i} - {\color{firebrick}u_j}$
    is more important than the arrival time ${\color{firebrick}u}$ itself,
    because the clock runs periodically.
-   In the early stages, fixing the timing violation could be done as soon as a negative cycle is detected.
    A complete timing analysis is unnecessary at this stage.

---

### Example 2 : Delay padding + clock skew scheduling ‚è∞

-   Goal: intentionally "insert" a delay $p$ so that the setup and hold time constraints are satisfied.
-   Note that a delay can be "inserted" by swapping a fast transistor into a slower transistor.
-   Traditional problem formulation: Find $p$ and ${\color{firebrick}u}$ such that

    $$\begin{array}{ll}
      {\color{blue}y} \leq {\color{blue}d} + p, \\
      {\color{green}A}  {\color{firebrick}u} = {\color{blue}y}, p \geq 0
    \end{array}$$

-   Note 1: Inserting delays into some local paths may not be allowed.
-   Note 2: The problem can be reduced to the standard form by modifying the network (timing constraint graph)

---

### Four possible ways to insert delay ‚è≥

.pull-left[

No delay:

![no\_delay](media/no_delay.svg)

$p_s = p_h$:

![same\_delay](media/same_delay.svg)

]
.pull-right[

Independent:

![independent](media/independent.svg)

$p_s \geq p_h$:

![setup\_greater](media/setup_greater.svg)

]

---

### Remarks (III)

-   If there exists a negative cycle, it means that timing cannot be fixed using simply this technique.

-   Additional constraints, such as $p_s \leq p_{\max}$, can be imposed.

---

class: nord-light, middle, center

Parametric Problems üìà
-------------------

---

### Parametric Potential Problem (PPP)

-   Consider a parameter potential problem: $$\begin{array}{ll}
      \text{maximize} & {\color{coral}\beta} \\
      \text{subject to} & {\color{blue}y} \leq {\color{olive}d}({\color{coral}\beta}), \\
      & {\color{green}A}  \cdot {\color{firebrick}u} = {\color{blue}y}
    \end{array}$$ where ${\color{olive}d}({\color{coral}\beta})$ is a *monotonic decreasing*
    function.

-   If ${\color{olive}d}({\color{coral}\beta})$ is a linear function $(m - s {\color{coral}\beta})$ where $s$ is non-negative,
    the problem reduces to the well-known *minimum cost-to-time ratio problem*.

-   If $s$ = constant, it further reduces to the *minimum mean cycle problem*.

**Note:** Parametric flow problem can be defined similarly.

---

### Examples (III)

-   ${\color{olive}d}({\color{coral}\beta})$ is linear $(m - s {\color{coral}\beta})$:

    -   Optimal clock period scheduling problem ‚è∞

    -   Slack maximization problem ‚è≥

    -   Yield-driven clock skew scheduling ‚è∞ (Gaussian)

-   ${\color{olive}d}({\color{coral}\beta})$ is non-linear:

    -   Yield-driven clock skew scheduling ‚è∞ (non-Gaussian)

    -   Multi-domain clock skew scheduling ‚è∞

---

### Examples (IV)

-   Lawler's algorithm (binary search based) üîç
-   Howard's algorithm (cycle cancellation) ‚ûñ
-   Young's algorithm (path based) üõ£Ô∏è
-   Burns' algorithm (path based) üõ£Ô∏è
    -   for clock period optimization problem (all elements of $s$ are either 0 or 1)
-   Several hybrid methods have also been proposed

---

### Remarks (IV)

-   Need to solve feasibility problems many times. üîÑ

-   Data structures, such as Fibonacci heap or spanning tree/forest, can be used to improve efficiency üå≥

-   For multi-parameter problems, the *ellipsoid method* can be used. üèà

-   Example 1: yield-driven clock skew scheduling ‚è∞ (c.f. lecture 5)

---

### Example 2: yield-driven delay padding ‚è≥

-   The problem can be reduced to the standard form by modifying the underlying constraint graph.

---

### Four possible way to insert delay ‚è≥

.pull-left[

No delay:

![no\_delay\_s](media/no_delay_s.svg)

$p_s = p_h$:

![same\_delay\_s](media/same_delay_s.svg)

]
.pull-right[

Independent:

![independent\_s](media/independent_s.svg)

$p_s \geq p_h$:

![setup\_greater\_s](media/setup_greater_s.svg)

]

---

class: nord-light, middle, center

Min-cost Flow/Potenial Problem üí∞
------------------------------

---

### Elementary Optimal Problems üíØ

-   Elementary Flow Problem:
    $$\begin{array}{ll}
      \text{min} & {\color{blue}d}^\mathsf{T} {\color{green}x} + p \\
      \text{s. t.} & {\color{green}c} \leq {\color{green}x}, \\
      & {\color{blue} A^\mathsf{T} } {\color{green}x} = {\color{firebrick}b}, \; {\color{firebrick}b}({\color{salmon}V})=0
    \end{array}$$

-   Elementary Potential Problem:
    $$\begin{array}{ll}
      \text{max} & {\color{firebrick}b}^\mathsf{T} {\color{firebrick}u} - ({\color{green}c}^\mathsf{T} {\color{blue}y} + q) \\
      \text{s. t.} & {\color{blue}y} \leq {\color{blue}d}, \\
      & {\color{green}A}  {\color{firebrick}u} = {\color{blue}y}
    \end{array}$$

---

### Elementary Optimal Problems (Cont'd) üîÑ

-   The problems are dual to each other if
    $p + q = -{\color{green}c}^\mathsf{T} {\color{blue}d}, ({\color{green}x} - {\color{green}c})^\mathsf{T}({\color{blue}d} - {\color{blue}y}) = 0, {\color{green}c} \leq {\color{green}x}, {\color{blue}y} \leq {\color{blue}d}$

-   Since
    ${\color{firebrick}b}^\mathsf{T} {\color{firebrick}u}$ =
    $({\color{blue} A^\mathsf{T} } {\color{green}x})^\mathsf{T} {\color{firebrick}u} = {\color{green}x}^\mathsf{T} {\color{green}A}  {\color{firebrick}u} = {\color{green}x}^\mathsf{T} {\color{blue}y},$
    $[\min]-[\max] = ({\color{blue}d}^\mathsf{T} {\color{green}x} + p) - ({\color{firebrick}b}^\mathsf{T} {\color{firebrick}u} - [{\color{green}c}^\mathsf{T} {\color{blue}y} + q])$
    =
    ${\color{blue}d}^\mathsf{T} {\color{green}x} + {\color{green}c}^\mathsf{T} {\color{blue}y} - {\color{green}x}^\mathsf{T} {\color{blue}y} + p + q = ({\color{green}x} - {\color{green}c})^\mathsf{T} ({\color{blue}d} - {\color{blue}y}) \geq 0$

-   $[\min] - [\max]$ when equality holds.

---

### Remark (V)

-   We can formulate a linear problem in primal or dual form, depending on which solution method is more appropriate:

    -   Incremental improvement of feasible solutions

    -   Design variables are in the integral domain:

        -   The max-flow problem (i.e. ${\color{blue}d}^\mathsf{T} = [-1, -1, \cdots, -1]^\mathsf{T}$) may be better solved by the dual method.

---

### Linear Optimal Problems

-   Optimal Flow Problem: $$\begin{array}{ll}
      \text{min} & {\color{blue}d}^\mathsf{T} {\color{green}x} + p \\
      \text{s. t.} & {\color{green}c^-} \leq {\color{green}x} \leq {\color{green}c^+}, \\
      & {\color{blue} A^\mathsf{T} } {\color{green}x} = {\color{firebrick}b}, \; {\color{firebrick}b}({\color{salmon}V})=0
    \end{array}$$

-   Optimal Potential Problem: $$\begin{array}{ll}
      \text{max} & {\color{firebrick}b}^\mathsf{T} {\color{firebrick}u} - ({\color{green}c}^\mathsf{T} {\color{blue}y} + q) \\
      \text{s. t.} & {\color{blue}d^-} \leq {\color{blue}y} \leq {\color{blue}d^+}, \\
      & {\color{green}A}  {\color{firebrick}u} = {\color{blue}y}
    \end{array}$$

---

### Linear Optimal Problems (II)

By modifying the network:

-   The problem can be reduced to the elementary case [pp.275-276]

piece of cake üç∞

-   Piece-wise linear convex cost can be reduced to this linear problem [p.239,p.260]

The problem has been extensively studied and has numerous applications.

---

### Remark (VI)

-   We can transform the cost function to be non-negative by reversing the orientation of the negative cost edges.

-   Then reduce the problem to the elementary case (or should we???)

---

### Algorithms for Optimal Flow Problems üíß

-   Successive shortest path algorithm üõ£Ô∏è
-   Cycle cancellation method ‚ûñ
    -   Iteratively insert additional minimal flows according to a negative cycle of the residual network until no negative cycles are found.
-   Scaling method ‚öñÔ∏è

---

### For Special Cases ‚≠ê

-   Max-flow problem (${\color{blue}d} = -[1, \cdots, 1]$)
    -   Ford-Fulkerson algorithm: iteratively insert additional minimal flows
        according to an augmented path of the residual network, until no augmented paths of the residual network are found.
    -   Pre-flow Push-Relabel algorithm (dual method???)
-   Matching problems ($[{\color{green}c^-}, {\color{green}c^+}] = [0, 1]$)
    -   Edmond's blossom algorithm üå∏

---

### Min-Cost Flow Problem (MCFP) üí∞

-   Problem Formulation: $$\begin{array}{ll}
      \text{min} & {\color{blue}d}^\mathsf{T} {\color{green}x} \\
      \text{s. t.} & 0 \leq {\color{green}x} \leq {\color{green}c}, \\
      & {\color{blue} A^\mathsf{T} } {\color{green}x} = {\color{firebrick}b}, \; {\color{firebrick}b}({\color{salmon}V})=0
    \end{array}$$

-   Algorithm idea: descent method: given a feasible
    ${\color{green}x_0}$, find a better solution
    ${\color{green}x_1} = {\color{green}x_0} + \alpha \cdot {\color{green}p}$, where $\alpha$
    is positive.

---

### General Descent Method

-   **Input**: $f(x)$, initial $x$
-   **Output**: optimal opt $x^*$
-   **while** not converged,
    1.  Choose descent direction $p$;
    2.  Choose the step size $\alpha$;
    3.  $x := x + \alpha \cdot p$;

---

### Some Common Descent Directions

-   Gradient descent: $p = -\nabla f(x)^\mathsf{T}$
-   Steepest descent:
-   $\triangle x_\text{nsd}$ = argmin$\{\nabla f(x)^\mathsf{T} v \mid \|v\|=1 \}$
-   $\triangle x_\text{sd} = \|\nabla f(x)\| \triangle x_\text{nsd}$ (un-normalized)
-   Newton's method: $p = -\nabla^2 f(x)^{-1} \nabla f(x)$
-   For convex problems, must satisfy $\nabla f(x)^\mathsf{T} p < 0$.

**Note:** Here, there is a natural way to choose $p$!

---

### Min-Cost Flow Problem (II) üí∞

-   Let ${\color{green}x_1} = {\color{green}x_0} + \alpha \cdot {\color{green}p}$, then we
    have: $$\begin{array}{lll}
      \text{min} & {\color{blue}d}^\mathsf{T} {\color{green}x_0} + \alpha {\color{blue}d}^\mathsf{T} {\color{green}p}  & \Rightarrow {\color{blue}d}^\mathsf{T} {\color{green}p} < 0 \\
      \text{s. t.} & -{\color{green}x_0} \leq \alpha \cdot {\color{green}p} \leq {\color{green}c} - {\color{green}x_0} & \Rightarrow \text{residual graph} \\
      & {\color{blue} A^\mathsf{T} } {\color{green}p} = 0 & \Rightarrow {\color{green}p} \text{ is a cycle!}
    \end{array}$$

-   In other words, choose ${\color{green}p}$ to be a negative cycle! ‚ûñ

    -   Simple negative cycle, or

    -   Minimum mean cycle

---

### Primal Method for MCFP üíß

-   **Input**: $G({\color{salmon}V},{\color{lime}E}), [{\color{green}c^-}, {\color{green}c^+}], {\color{blue}d}$
-   **Output**: optimal opt ${\color{green}x^*}$
-   Initialize a feasible ${\color{green}x}$ and certain data structure
-   **while** a negative cycle ${\color{green}p}$ found in $G({\color{green}x})$,
    1.  Choose a step size $\alpha$;
    2.  **If** $\alpha$ is unbounded, **return** UNBOUNDED;
    3.  **If** $\alpha = 0$, **break**;
    4.  ${\color{green}x} := {\color{green}x} + \alpha \cdot {\color{green}p}$;
    5.  Update corresponding data structures
-   **return** OPTIMAL

---

### Remarks (VI)

-   In Step 4, negative cycle can be found using Bellman-Ford algorithm. ‚è±Ô∏è

-   In the cycle cancelling algorithm, ${\color{green}p}$ is:

    -   a simple negative cycle, or

    -   a minimum mean cycle

-   A heap or other data structures are used for finding negative cycles efficiently. üå≥

-   Usually $\alpha$ is chosen such that one constraint is tight.

---

### Min-Cost Potential Problem (MCPP) ‚ö°

-   Problem formulation: $$\begin{array}{ll}
      \text{min}   & {\color{green}c}^\mathsf{T} {\color{blue}y} \\
      \text{s. t.} & {\color{blue}y} \leq {\color{blue}d}, \\
      & {\color{green}A}  {\color{firebrick}u} = {\color{blue}y}
    \end{array}$$ where $c$ is assumed to be non-negative.

-   Algorithm: given an initial feasible ${\color{firebrick}u_0}$, find a better sol'n ${\color{firebrick}u_1} = {\color{firebrick}u_0} + \beta \cdot {\color{firebrick}q}$, where $\beta$ is positive:
    $$\begin{array}{lll}
      \text{min} & {\color{green}c}^\mathsf{T} {\color{blue}y_0} + {\color{green}c}^\mathsf{T} {\color{blue}y}  & \Rightarrow {\color{green}c}^\mathsf{T} {\color{blue}y} < 0 \\
      \text{s. t.} & {\color{blue}y} \leq {\color{blue}d} - {\color{green}A}  {\color{firebrick}u_0} & \Rightarrow \text{residual graph} \\
      & \beta {\color{green}A}  {\color{firebrick}q} = {\color{blue}y}    & \Rightarrow {\color{firebrick}q} \; \text{is a ``cut''!}
    \end{array}$$

---

### Method for MCPP ‚ö°

-   **Input**: $G({\color{salmon}V},{\color{lime}E}), {\color{green}c}, {\color{blue}d}$
-   **Output**: optimal opt ${\color{firebrick}u^*}$
-   Initialize a feasible ${\color{firebrick}u}$ and certain data structure
-   **while** a negative cut ${\color{firebrick}q}$ found in $G({\color{firebrick}u})$,
    1.  Choose a step size $\beta$;
    2.  **If** $\beta$ is unbounded, **return** UNBOUNDED;
    3.  **If** $\beta = 0$, **break**;
    4.  ${\color{firebrick}u} := {\color{firebrick}u} + \beta \cdot {\color{firebrick}q}$;
    5.  Update corresponding data structures
-   **return** OPTIMAL

---

### Remarks (VII) üìù

-   Usually $\beta$ is chosen such that one constraint is tight.

-   The min-cost potential problem is the dual of the min-cost flow problem, so algorithms can solve both problems.

-   In the network simplex method, ${\color{firebrick}q}$ is chosen from a spanning tree data structure (for linear problems only)

---

count: false
class: nord-dark, middle, center

Q&A üé§
==========
    </textarea>
    <script src="../js/remark.min.js"></script>
    <script src="../js/quasar.umd.min.js"></script>
    <script src="../js/mermaid.min.js"></script>
    <script src="../katex/katex.min.js" type="text/javascript"></script>
    <script
      src="../katex/contrib/auto-render.min.js"
      type="text/javascript"
    ></script>
    <script>
      renderMathInElement(document.getElementById("source"), {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
        ],
      });
      var slideshow = remark.create({
        ratio: "4:3", // Á™óÂè£ÊØî‰æã
        // ÂèØÈÄâÔºöarta, ascetic, dark, default, far, github, googlecode, idea,
        // ir-black, magula, monokai, rainbow, solarized-dark, solarized-light,
        // sunburst, tomorrow, tomorrow-night-blue, tomorrow-night-bright,
        // tomorrow-night, tomorrow-night-eighties, vs, zenburn.
        highlightStyle: "tomorrow-night-eighties",
        highlightLines: true,
        countIncrementalSlides: false, // Â¢ûÈáèÂÜÖÂÆπÊòØÂê¶ÁÆó‰∏ÄÈ°µ
        // slideNumberFormat: "", // Ëã•Â∞ÜÊ≠§ÂèÇÊï∞ËÆæÁΩÆ‰∏∫ ""ÔºåÂ∞Ü‰∏çÊòæÁ§∫È°µÁ†Å
        navigation: {
          scroll: false, // ÊòØÂê¶ÂÖÅËÆ∏‰ΩøÁî®Èº†Ê†áÊªöËΩÆÁøªÈ°µ
          touch: true, // ÔºàÂ¶ÇÊûúÊòØËß¶Êë∏Â±èÔºâÊòØÂê¶ÂÖÅËÆ∏ÁÇπÂáªÂ±èÂπïÂ∑¶ËæπÊàñÂè≥ËæπÂâçÂêéÁøªÈ°µ
          click: false, // ÊòØÂê¶ÂÖÅËÆ∏Èº†Ê†áÁÇπÂáªÂ±èÂπïÂ∑¶ËæπÊàñÂè≥ËæπÂâçÂêéÁøªÈ°µ
        },
      });

      // ÂàùÂßãÂåñ VUE
      for (var el of document.querySelectorAll(".vue")) {
        new Vue({
          el: el,
        });
      }

      // ÂàùÂßãÂåñÂèØÁÇπÂáªÈ¢ÑËßàÁöÑÂç°Áâá
      var preview_win_cards = document.querySelectorAll(".preview-win");
      for (var card of preview_win_cards) {
        ((clickedCard) => {
          clickedCard.addEventListener("click", (e) => {
            var img = clickedCard.querySelector("img");
            if (img) {
              window.open(img.src);
            }
          });
        })(card);
      }

      // ËÉåÊôØËâ≤ÂèòÂåñÂÖºÂÆπ F11 ÂÖ®Â±è
      function isFullScreen() {
        return (
          window.fullScreen ||
          (window.innerWidth == screen.width &&
            window.innerHeight == screen.height)
        );
      }

      window.addEventListener("resize", () => {
        if (isFullScreen()) {
          document.body.style["background-color"] = "#000";
        } else {
          document.body.style["background-color"] = "#d7d8d2";
        }
      });

      // ÂàùÂßãÂåñ mermaid
      mermaid.mermaidAPI.initialize({
        startOnLoad: false,
        theme: "forest",
        themeCSS:
          ".tick>text { font-size:26px; }  .taskTextOutsideRight,.taskTextOutsideLeft { font-size:20px; } .titleText {font-size:30px;} .sectionTitle {font-size:20px;}",
        gantt: {
          fontSize: 26,
          barHeight: 30,
          useMaxWidth: false,
        },
      });

      var mermaidCmps = document.querySelectorAll(".mermaid");
      for (var i = 0; i < mermaidCmps.length; i++) {
        var mermaidCmp = mermaidCmps[i];
        var insertSvg = function (svgCode, bindFunctions) {
          mermaidCmp.innerHTML = svgCode;
        };

        var graphDefinition = "";
        let pCmps = mermaidCmp.querySelectorAll("pre");
        for (var pCmp of pCmps) {
          graphDefinition += pCmp.textContent.replace(/\\n/g, "<br/>");
        }

        var graph = mermaid.mermaidAPI.render(
          "graphDiv" + i,
          graphDefinition,
          insertSvg,
        );
      }
    </script>
  </body>
</html>
